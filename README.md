# ChatGPT Platform with Mistral LLM

A simple ChatGPT-like web platform built with React frontend and Node.js backend, deployed on Kubernetes using Helm, and integrated with a local Mistral LLM server.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React         â”‚    â”‚   Node.js       â”‚    â”‚   Mistral LLM   â”‚
â”‚   Frontend      â”‚â—„â”€â”€â–ºâ”‚   Backend       â”‚â—„â”€â”€â–ºâ”‚   Server        â”‚
â”‚   (Port 3000)   â”‚    â”‚   (Port 3001)   â”‚    â”‚   (Port 1234)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **Docker** and **Docker Compose**
- **Kubernetes** cluster (local or remote)
- **Helm** v3.x
- **kubectl** configured
- **Mistral LLM server** running on `http://127.0.0.1:1234`

## ğŸš€ Quick Start

### Option 1: Docker Compose (Easiest)

1. **Start Mistral LLM server** (in a separate terminal):
   ```bash
   # Example with vLLM
   python -m vllm.entrypoints.openai.api_server \
     --model mistralai/Mistral-7B-Instruct-v0.1 \
     --port 1234
   ```

2. **Run the platform**:
   ```bash
   ./deployment/local/quick-start.sh
   ```

3. **Access the application**:
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:3001

### Option 2: Kubernetes with Helm

1. **Build and deploy**:
   ```bash
   ./deployment/local/deploy.sh
   ```

2. **Set up port forwarding**:
   ```bash
   ./deployment/local/port-forward.sh
   ```

3. **Access the application**:
   - Frontend: http://localhost:8080
   - Backend API: http://localhost:3001

## ğŸ“ Project Structure

```
k8s_vLLM/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ helm-chart/                 # Helm chart for Kubernetes deployment
â”‚   â”œâ”€â”€ Chart.yaml
â”‚   â”œâ”€â”€ values.yaml
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ _helpers.tpl
â”‚       â”œâ”€â”€ configmap.yaml
â”‚       â”œâ”€â”€ frontend-deployment.yaml
â”‚       â”œâ”€â”€ frontend-service.yaml
â”‚       â”œâ”€â”€ backend-deployment.yaml
â”‚       â”œâ”€â”€ backend-service.yaml
â”‚       â”œâ”€â”€ ingress.yaml
â”‚       â””â”€â”€ NOTES.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ frontend/               # React frontend application
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ App.js
â”‚   â”‚       â”œâ”€â”€ App.css
â”‚   â”‚       â”œâ”€â”€ index.js
â”‚   â”‚       â””â”€â”€ components/
â”‚   â”‚           â””â”€â”€ ChatInterface.js
â”‚   â””â”€â”€ backend/                # Node.js Express backend
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ package.json
â”‚       â”œâ”€â”€ server.js
â”‚       â”œâ”€â”€ .env.example
â”‚       â””â”€â”€ routes/
â”‚           â””â”€â”€ chat.js
â””â”€â”€ deployment/
    â””â”€â”€ local/
        â”œâ”€â”€ deploy.sh           # Build and deploy script
        â”œâ”€â”€ port-forward.sh     # Port forwarding for local access
        â””â”€â”€ quick-start.sh      # Quick start with Docker Compose
```

## ğŸ”§ Configuration

### Environment Variables

**Backend (.env)**:
```bash
NODE_ENV=development
PORT=3001
MISTRAL_API_URL=http://127.0.0.1:1234
FRONTEND_URL=http://localhost:3000
MISTRAL_TIMEOUT=30000
```

**Frontend**:
```bash
REACT_APP_BACKEND_URL=http://localhost:3001
```

### Helm Values

Edit `helm-chart/values.yaml` to customize:

```yaml
backend:
  env:
    MISTRAL_API_URL: "http://host.docker.internal:1234"
    
ingress:
  enabled: true
  hosts:
    - host: chatgpt-local.dev
```

## ğŸ³ Docker Commands

### Build Images
```bash
# Frontend
docker build -t chatgpt-frontend:latest ./src/frontend

# Backend  
docker build -t chatgpt-backend:latest ./src/backend
```

### Run with Docker Compose
```bash
# Start services
docker-compose up --build

# Run in background
docker-compose up -d --build

# Stop services
docker-compose down
```

## â˜¸ï¸ Kubernetes Commands

### Deploy with Helm
```bash
# Install
helm install chatgpt-platform ./helm-chart

# Upgrade
helm upgrade chatgpt-platform ./helm-chart

# Uninstall
helm uninstall chatgpt-platform
```

### Manual Kubernetes Commands
```bash
# Create namespace
kubectl create namespace chatgpt

# Deploy to specific namespace
helm install chatgpt-platform ./helm-chart -n chatgpt

# Port forward
kubectl port-forward svc/chatgpt-platform-frontend 8080:80
kubectl port-forward svc/chatgpt-platform-backend 3001:80

# Check logs
kubectl logs -l app.kubernetes.io/component=frontend
kubectl logs -l app.kubernetes.io/component=backend

# Check pods
kubectl get pods -l app.kubernetes.io/instance=chatgpt-platform
```

## ğŸ§ª Testing

### Test Backend API
```bash
# Health check
curl http://localhost:3001/health

# Test Mistral connection
curl http://localhost:3001/chat/test

# Send chat message
curl -X POST http://localhost:3001/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello, how are you?"}'
```

### Test Frontend
- Open http://localhost:3000 (Docker) or http://localhost:8080 (Kubernetes)
- Type a message and press send
- Verify response from Mistral LLM

## ğŸ” Troubleshooting

### Common Issues

1. **Mistral API not accessible**:
   ```bash
   # Check if Mistral server is running
   curl http://127.0.0.1:1234/v1/models
   
   # For Docker: Use host.docker.internal:1234
   # For Kubernetes: Update values.yaml with correct endpoint
   ```

2. **Frontend can't reach backend**:
   ```bash
   # Check backend health
   curl http://localhost:3001/health
   
   # Verify CORS settings in backend
   # Check REACT_APP_BACKEND_URL environment variable
   ```

3. **Kubernetes pods not starting**:
   ```bash
   # Check pod status
   kubectl get pods -l app.kubernetes.io/instance=chatgpt-platform
   
   # Check logs
   kubectl logs -l app.kubernetes.io/component=backend
   
   # Describe pod for events
   kubectl describe pod <pod-name>
   ```

4. **Port forwarding issues**:
   ```bash
   # Kill existing port forward processes
   pkill -f "kubectl port-forward"
   
   # Start fresh port forwarding
   ./deployment/local/port-forward.sh
   ```

## ğŸ¯ Features

- âœ… Real-time chat interface
- âœ… Message history display
- âœ… Loading indicators during LLM processing
- âœ… Error handling for API failures
- âœ… Responsive design
- âœ… Markdown support in responses
- âœ… Docker containerization
- âœ… Kubernetes deployment with Helm
- âœ… Health checks and monitoring
- âœ… CORS and security headers
- âœ… Rate limiting
- âœ… Graceful error handling

## ğŸ”’ Security

- Helmet.js for security headers
- CORS configuration
- Rate limiting (100 requests per 15 minutes)
- Input validation and sanitization
- Non-root Docker containers
- Health checks for container monitoring

## ğŸ“ˆ Monitoring

### Health Endpoints
- Frontend: `http://localhost:3000/` (returns React app)
- Backend: `http://localhost:3001/health` (returns JSON status)
- Backend Test: `http://localhost:3001/chat/test` (tests Mistral connection)

### Kubernetes Health Checks
- Liveness probes for automatic restart on failure
- Readiness probes for traffic routing
- Resource limits and requests defined

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test locally with Docker Compose
5. Test with Kubernetes
6. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

For issues and questions:
1. Check the troubleshooting section
2. Review logs: `kubectl logs -l app.kubernetes.io/instance=chatgpt-platform`
3. Test components individually
4. Open an issue on GitHub
